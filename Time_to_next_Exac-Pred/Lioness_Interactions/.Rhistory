while (counter<100){
data_p[[x_nam]]<-sample(data_p[[x_nam]])
#renormalization
data_p=(data_p/rowSums(data_p))
out<-boot.stat(data_p,indices = 1:dim(data)[1],m_stop=opt_m,form=form,x_nam=x_nam)
out_comb=rbind(out_comb,out)
counter = counter + 1
}
out_comb<-out_comb[-1,]
#Comparing two distributions
p_test<-c()
for (i in 1:dim(out_comb)[2]){
p=wilcox.test(model.boot$t[,i],out_comb[,i],alternative = "two.sided",paired = FALSE)$p.value
p_test<-c(p_test,p)
}
#correction of multiple comparision
p_test<-p.adjust(p_test,method = "fdr")
for (i in 1:dim(out_comb)[2]){
p_m[x_nam,colnames(out_comb)[i]]<-p_test[i]
}
}
m #adjaceny matrix
p_m #p-value matrix
ind<-(p_m>0.001) #p-value is non-significant
library(lionessR)
library(SummarizedExperiment)
data=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
data<-t(data)
# print("started")
library(mboost)
# For c1_data
cr_mat=cor(data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(data))
p_m<-data.frame(p_m,row.names = colnames(data))
colnames(m)<-colnames(data)
colnames(p_m)<-colnames(data)
r2<-function(model,col=i,data=data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
i=1
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05 and != 1
y_nam
x_nam
# print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=as.data.frame(data),family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=FALSE))
summary(model1)
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10)
cvm<-cvrisk(model1,folds=f,mc.cores=4)
f
cvm<-cvrisk(model1,folds=f,mc.cores=4)
cvm
library(lionessR)
library(SummarizedExperiment)
data=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
data<-as.matrix(data)
data<-t(data)
<
data<-t(data)
# print("started")
library(mboost)
# For c1_data
cr_mat=cor(data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(data))
p_m<-data.frame(p_m,row.names = colnames(data))
colnames(m)<-colnames(data)
colnames(p_m)<-colnames(data)
r2<-function(model,col=i,data=data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
i=1
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05 and != 1
if(identical(y_nam,character(0)) == TRUE){next}
# print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=as.data.frame(data),family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=FALSE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10) # ==== error===============
x
model1
coef(model1)
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10) # ==== error===============
cvm<-cvrisk(model1,folds=f,mc.cores=4)
install.packages("mboost")
install.packages("mboost")
install.packages("mboost")
install.packages("mboost")
library(lionessR)
library(SummarizedExperiment)
data=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
data<-t(data)
#Mutual Information
library("minet")
m<-build.mim(data,estimator = "mi.mm",disc = "equalwidth")
net<-aracne(m)
Adj<-net
Adj
#Bootstrap
max_iter=100
rows=rownames(data)
boot_arr<-array(dim=c(dim(net)[1],dim(net)[1],max_iter))
for (i in 1:max_iter){
t_x=sample(rows,replace = TRUE)
m=build.mim(data[t_x,],estimator = "mi.mm",disc = "equalwidth")
net<-aracne(m)
boot_arr[,,i]<-net
}
#perm and renorm
max_iter=100
perm_arr<-array(dim=c(dim(net)[1],dim(net)[1],max_iter))
for (i in 1:max_iter){
x<-apply(data,2,FUN =sample) #permutation
x<-x/rowSums(x) #renormalization
m=build.mim(x,estimator = "mi.mm",disc = "equalwidth")
net<-aracne(m)
print(sum(is.na(net)))
perm_arr[,,i]<-net
}
#Converting NA to 0
boot_arr[is.na(boot_arr)]<-0
perm_arr[is.na(perm_arr)]<-0
p_val=array(dim=c(dim(net)[1],dim(net)[1]))
for (i in 1:dim(net)[1]){
for (j in 1:dim(net)[1]){
t=wilcox.test(perm_arr[i,j,],boot_arr[i,j,],alternative = "two.sided",paired = FALSE,exact = TRUE)
p_val[i,j]<-t$p.value
}
}
p<-p.adjust(p_val,method = "fdr")
dim(p)<-dim(p_val)
p #p-value
p>0.01
Adj
ind<-(p>0.001) #p-value is non-significant
Adj[ind]<-0 #make those edges 0
Adj
library(lionessR)
library(SummarizedExperiment)
data=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
source("MI.R")
data<-as.matrix(data)
data<-t(data)
res<-lioness(data,MI)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
print(t(res))
summary(t(res))
apply(t(res),var)
?apply
apply(t(res),1,var)
apply(t(res),2,var)
write.csv(t(res),"edge_weights-across_patients.csv")
source('~/OneDrive/3.SNF/Nature_Med-resubmission/Time_to_next_Exac-Pred/Lioness/try.R', echo=TRUE)
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/BSL_C2/Microbes.csv",row.names = 1)
data1
data2
colnames(data1)==colnames(data2)
data=rbind(data1,data2)
source("MI.R")
data<-as.matrix(data)
data<-t(data)
res<-lioness(data,MI)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
print(t(res))
apply(t(res),2,var)
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/BSL_C2/Microbes.csv",row.names = 1)
data=rbind(data1,data2)
source("MI.R")
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
res<-lioness(data,GBLM)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
res<-t(res)
#filtering edges with no-variance
ind<-apply(res,2,var)>0
res<-res[,ind]
y<-read.csv("./../Pre-processing/Pre-processed/bac_BSL.csv",row.names = 1)
y=as.data.frame(y$Time.to.next.exacerbation,row.names = row.names(y))
res<-merge(res,y,by="row.names",all=TRUE);row.names(res)<-res$Row.name;res$Row.names<-NULL
#==========Correlation plot=============
library("Hmisc")
library(corrplot)
data=res
res<-rcorr(as.matrix(data),type="spearman")
ind<-(res$P[1,]<0.05)
ind[1]<-TRUE #first
y<-as.data.frame(res$r[1,])
y[(ind == FALSE),]<-0
write.csv(y,"BSL.csv")
library(compositions)
f_selected=list()
for(i in c("BSL","EX1","P1")){
X_m<-NA
for(j in c("bac","fungi","vir")){
nam=paste0(j,"_",i)
print(nam)
data<-read.csv(paste0("./../Pre-processing/Pre-processed/",nam,".csv"),row.names = 1)
t_ex=data$Time.to.next.exacerbation
y<-ifelse(data$Time.to.next.exacerbation<7*12,"1","2")
X<-data[,1:(dim(data)[2]-1)]
X=as.data.frame(clr(X))
X_m=cbind(X_m,X)
}
X_m$X_m<-as.factor(y)
#Feature_selection
data<-read.csv(paste0("./../Co-occurence_Analysis/",i,"_C1/Microbes.csv"),row.names = 1)
sel<-colnames(data)
f_sel=X_m[c("X_m",sel)]
f_selected[[i]]<-f_sel
}
#Co-relation plot
#===========Correlation Plot================
library("Hmisc")
library(corrplot)
library(earth)
model<-earth(X_m ~ .,data = f_selected$BSL,degree = 10)
data=evimp(model)
data = as.data.frame(unclass(data[,c(3,4,6)]))
data$var<-row.names(data)
data
f_imp_data=list()
f_imp_data$BSL<-data
f_imp_data
model<-earth(X_m ~ .,data = f_selected$EX1,degree = 10)
summary(model)
data=evimp(model)
data = as.data.frame(unclass(data[,c(3,4,6)]))
data$var<-row.names(data)
data
data=evimp(model)
data
data<-as.data.frame(unclass(data))
data$var<-row.names(data)
data
f_imp_data$EX!<-data
f_imp_data$EX1<-data
f_imp_data
model<-earth(X_m ~ .,data = f_selected$P1,degree = 10)
summary(model)
data=evimp(model)
data = as.data.frame(unclass(data[,c(3,4,6)]))
data$var<-row.names(data)
data
f_imp_data$P1<-data
f_imp_data
saveRDS(f_imp_data,"feature_importance_data.RDS")
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/BSL_C2/Microbes.csv",row.names = 1)
data=rbind(data1,data2)
source("MI.R")
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
res<-lioness(data,GBLM)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
res<-t(res)
#filtering edges with no-variance
ind<-apply(res,2,var)>0
res<-res[,ind]
y<-read.csv("./../Pre-processing/Pre-processed/bac_BSL.csv",row.names = 1)
y=as.data.frame(y$Time.to.next.exacerbation,row.names = row.names(y))
res<-merge(res,y,by="row.names",all=TRUE);row.names(res)<-res$Row.name;res$Row.names<-NULL
#==========Correlation plot=============
library("Hmisc")
library(corrplot)
data=res
res<-rcorr(as.matrix(data),type="spearman")
ind<-(res$P[1,]<0.05)
ind[1]<-TRUE #first
y<-as.data.frame(res$r[1,])
y[(ind == FALSE),]<-0
write.csv(y,"BSL.csv")
library(earth)
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
data
summary(model)
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
data
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
res
data
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/BSL_C2/Microbes.csv",row.names = 1)
data=rbind(data1,data2)
source("MI.R")
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
res<-lioness(data,GBLM)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
res<-t(res)
#filtering edges with no-variance
ind<-apply(res,2,var)>0
res<-res[,ind]
y<-read.csv("./../Pre-processing/Pre-processed/bac_BSL.csv",row.names = 1)
y=as.data.frame(y$Time.to.next.exacerbation,row.names = row.names(y))
res<-merge(res,y,by="row.names",all=TRUE);row.names(res)<-res$Row.name;res$Row.names<-NULL
data=res
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
data=evimp(model)
data = as.data.frame(unclass(data[,c(3,4,6)]))
data$var<-row.names(data)
data
set.seed(123)
res<-lioness(data,GBLM)
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/BSL_C2/Microbes.csv",row.names = 1)
data=rbind(data1,data2)
source("MI.R")
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
set.seed(123)
res<-lioness(data,GBLM)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
res<-t(res)
#filtering edges with no-variance
ind<-apply(res,2,var)>0
res<-res[,ind]
write.csv(res,"edge_weights-across_patients.csv")
y<-read.csv("./../Pre-processing/Pre-processed/bac_BSL.csv",row.names = 1)
y=as.data.frame(y$Time.to.next.exacerbation,row.names = row.names(y))
res<-merge(res,y,by="row.names",all=TRUE);row.names(res)<-res$Row.name;res$Row.names<-NULL
data=res
library(earth)
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
summary(model)
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/BSL_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/BSL_C2/Microbes.csv",row.names = 1)
data=rbind(data1,data2)
source("MI.R")
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
set.seed(123)
res<-lioness(data,GBLM)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
res<-t(res)
#filtering edges with no-variance
ind<-apply(res,2,var)>0
res<-res[,ind]
y<-read.csv("./../Pre-processing/Pre-processed/bac_BSL.csv",row.names = 1)
y=as.data.frame(y$Time.to.next.exacerbation,row.names = row.names(y))
res<-merge(res,y,by="row.names",all=TRUE);row.names(res)<-res$Row.name;res$Row.names<-NULL
#==========Correlation plot=============
library("Hmisc")
library(corrplot)
data=res
library(earth)
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
sink("BSL.txt")
summary(model)
sink()
data=evimp(model)
data = as.data.frame(unclass(data[,c(3,4,6)]))
data$var<-row.names(data)
data
write.csv(data,"BSL.csv")
data=res
res<-rcorr(as.matrix(data),type="spearman")
ind<-(res$P[1,]<0.05)
ind[1]<-TRUE #first
y<-as.data.frame(res$r[1,])
y[(ind == FALSE),]<-0
write.csv(y,"BSL.csv")
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/EX1_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/EX1_C2/Microbes.csv",row.names = 1)
data=rbind(data1,data2)
source("MI.R")
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
set.seed(123)
res<-lioness(data,GBLM)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
res<-t(res)
#filtering edges with no-variance
ind<-apply(res,2,var)>0
res<-res[,ind]
write.csv(res,"edge_weights-across_patients.csv")
y<-read.csv("./../Pre-processing/Pre-processed/bac_BSL.csv",row.names = 1)
y=as.data.frame(y$Time.to.next.exacerbation,row.names = row.names(y))
res<-merge(res,y,by="row.names",all=TRUE);row.names(res)<-res$Row.name;res$Row.names<-NULL
#==========Correlation plot=============
library("Hmisc")
library(corrplot)
data=res
library(earth)
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
sink("EX1.txt")
summary(model)
sink()
data=evimp(model)
data = as.data.frame(unclass(data[,c(3,4,6)]))
data$var<-row.names(data)
data
write.csv(data,"EX1.csv")
data=res
res<-rcorr(as.matrix(data),type="spearman")
ind<-(res$P[1,]<0.05)
ind[1]<-TRUE #first
y<-as.data.frame(res$r[1,])
y[(ind == FALSE),]<-0
write.csv(y,"EX1.csv")
library(lionessR)
library(SummarizedExperiment)
data1=read.csv("./../Co-occurence_Analysis/P1_C1/Microbes.csv",row.names = 1)
data2=read.csv("./../Co-occurence_Analysis/P1_C2/Microbes.csv",row.names = 1)
data=rbind(data1,data2)
source("MI.R")
source("GBLM.R")
data<-as.matrix(data)
data<-t(data)
set.seed(123)
res<-lioness(data,GBLM)
print(dim(assay(res)))
res<-as.data.frame(assay(res))
res<-t(res)
#filtering edges with no-variance
ind<-apply(res,2,var)>0
res<-res[,ind]
y<-read.csv("./../Pre-processing/Pre-processed/bac_BSL.csv",row.names = 1)
y=as.data.frame(y$Time.to.next.exacerbation,row.names = row.names(y))
res<-merge(res,y,by="row.names",all=TRUE);row.names(res)<-res$Row.name;res$Row.names<-NULL
#==========Correlation plot=============
library("Hmisc")
library(corrplot)
data=res
library(earth)
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
sink("P1.txt")
summary(model)
sink()
model<-earth(`y$Time.to.next.exacerbation` ~ .,data = data,degree = 10)
summary(model)
data=evimp(model)
data = as.data.frame(unclass(data[,c(3,4,6)]))
data$var<-row.names(data)
data
write.csv(data,"P1.csv")
data=res
res<-rcorr(as.matrix(data),type="spearman")
ind<-(res$P[1,]<0.05)
ind[1]<-TRUE #first
y<-as.data.frame(res$r[1,])
y[(ind == FALSE),]<-0
write.csv(y,"P1.csv")
